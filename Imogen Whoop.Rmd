---
title: "Metric Analysis"
author: "Imogen Meers"
date: "26/1/24"
output: html_document
---

# Personal Whoop Analysis: What makes the Optimal Taper?

## Motivation

Taper is one of the hardest but also most important parts of the swimming cycle to execute. Years of training can come to fruition with a good taper, but swimmers often fall short if they "miss" their taper.

This is an important problem to me personally as I am using my own Whoop data from my college experience (2020-2025) to decipher what are important features of taper for me and what I can optimize/avoid in order to have a "peak performance."

Whilst it will be useful to see how Whoop affects taper and competition, it is important to note that this analysis is a small snapshot of my actions that affect my swimming. I am not including injury, illness, nutrition or recovery data, which would help to draw a better picture of my performance. I am, however, hoping that significant changes in these areas will be reflected in my personal metrics and thus be considered.

## Previous Work

There have been a number of studies on wearable tech metrics and their accuracy and predictability for factors of performance, recovery and strain. 

One study I found that was particularly interesting and related to my analysis is the thesis of Emily Lundstrom, a Masters student at Penn State University called _Effectiveness of Wearable Technology for Predicting Measures of Metabolism and Performance in Collegiate Division 1 Swimmers_. She found a negative correlation between strain and time trial performance in female swimmers as well as a positive correlation between HRV and suppressed metabolic rate. These are both significant findings when looking at Whoop metrics in swimmers and are similar to what I would expect to find in my own analysis. 


## Problem Framing

After an exploratory analysis of the different data sets collected by Whoop, which include physiology, sleep and workouts, I intend to analyse different parts of this problem.

1. What factors contribute the most to my peak performances?
  For this, I will use both my own derived variables such as AC ratio, and Whoop's derived metrics to create a model that predicts performance and extract variable importance. 
  
  
2. How my performance varies between events, based on taper?
  For this, I will extract more data from my swims and look at distribution of splits and overall results for 50 vs 100 and how factors differ between good performances in front-end vs. back-end speed.


## Data Overview

My data sources will be:

Whoop metrics from July 2020 to Jan 2025

  - Whoop derived variables:
      - Physiological
      - Sleep
      - Workout
      
  - Self derived variables
      - AC Ratios
      - Rolling average
      - Workout description indicator variables
  
swimcloud.com meet results from July 2020 to Jan 2025

This data is generally pretty clean and comprehensive. I have worn my Whoop consistently for the past 4 years with only a few days missing data. I do take off my Whoop when I am competing, but this should not affect my analysis as I am using results-based data to evaluate success of a meet rather than in-meet Whoop metrics.

The swimcloud website is also a reliable data source. They report times for all meets and splits for most, meaning there is no need to impute data here.

## Bibliography

Lundstrom, E. (2020). Effectiveness of Wearable Technology for Predicting Measures of Metabolism and Performance in Collegiate Division 1 Swimmers. Master's Thesis, Pennsylvania State University1. Retrieved from Pennsylvania State University Electronic Theses and Dissertations.

## Preliminary EDA

Let's load in the packages we are going to use for the analysis:

```{r warning=FALSE}
library(ggplot2) # load ggplot2
library(ggdark) # load ggdark
library(data.table) # load data.table
library(dplyr)
library(lubridate)
library(tidyr)
library(stringr)
```



```{r}
phys_cycles <- read.csv("physiological_cycles.csv")
dim(phys_cycles) # View dimensions of the data
plot_data <- phys_cycles 
colnames(plot_data) <- c("cycle_start", "cycle_end", "cycle_tzone", "recovery", "rhr", "hrv", "skin_temp", "blood_oxygen", "day_strain", "energy_burned", "maxhr", "ahr", "sleep_onset", "wake_onset", "sleep_performance", "resp_rate", "asleep_dur", "in_bed_dur", "light_sleep", "deep_sleep", "rem", "awake_dur", "sleep_need", "sleep_debt", "sleep_efficiency", "sleep_consistency")

summary(plot_data) # Summarise metric data
```
This data has 1477 rows dating from July 2020 to present. It includes general data on physiological cycles including sleep and  daily metrics.
```{r}
  # Create a mapping of time zone offsets to Olson names
  tzone_mapping <- c(
    "UTC-05:00" = "America/New_York",
    "UTCZ" = "UTC",
    "UTC-06:00" = "America/Chicago",
    "UTC-07:00" = "America/Denver",
    "UTC-04:00" = "America/Halifax",
    "UTC+02:00" = "Europe/Bucharest",
    "UTC+01:00" = "Europe/Paris"
  )

  grade_mapping <- function(date) {
    #' This calculates grade based on date range
    #'
    #' @param date the date to find the grade from
    #' 
    #' @return grade as string
    #'
    #'
    
    
    
    if (date >= as.Date("2020-08-01") & date < as.Date("2021-05-01")) {
      return("Freshman")
    } else if (date >= as.Date("2021-05-01") & date < as.Date("2022-05-01")) {
      return("Sophomore")
    } else if (date >= as.Date("2022-05-01") & date < as.Date("2023-05-01")) {
      return("Junior")
    } else if (date >= as.Date("2023-05-01") & date < as.Date("2024-05-01")) {
      return("Senior")
    } else if (date >= as.Date("2024-05-01")) {
      return("Grad")
    } else {
      return(NA)  # In case date does not fall within any range
    }
  }




  days_since_mapping <- function(grade, date) {
    
  #' This calculates number of days since the start of the season depending on grade (rowwise)
  #'
  #' @param grade the grade as a string
  #' @param date the date to find the difference from
  #' 
  #' @return number of days from date
  #'
  #'
    if (is.na(grade)){
      return(NA)
    }
    
    
    if (grade == "Freshman") {
      reference_date = "2020-05-01"
      return(as.integer(difftime(date, reference_date, units = "days")))
    } else if (grade == "Sophomore") {
      reference_date = "2021-05-01"
      return(as.integer(difftime(date, reference_date, units = "days")))
    } else if (grade == "Junior") {
      reference_date = "2022-05-01"
      return(as.integer(difftime(date, reference_date, units = "days")))
    } else if (grade == "Senior") {
        reference_date = "2023-05-01"
        return(as.integer(difftime(date, reference_date, units = "days")))
    } else {
        reference_date = "2024-05-01"
        return(as.integer(difftime(date, reference_date, units = "days")))
    }
  }

date_cleaning <- function(plot_data){
  #'
  #' This function cleans up the dates, and assigns years and days since the start of the period
  #'
  #' @param plot_data the unclean df
  #' 
  #' @return A cleaned df with appropriate manipulated and added fields
  #'

  

  
  # Apply mapping of tzone
  plot_data <- plot_data %>%
    mutate(cycle_olson = tzone_mapping[cycle_tzone])
  
  # Convert to dates, but also converts tzone to UTC (don't want) so force_tz
  plot_data <- plot_data %>% rowwise() %>%
    mutate(cycle_start = force_tz(ymd_hms(cycle_start, tz = cycle_olson)),
           cycle_end = force_tz(ymd_hms(cycle_end, tz = cycle_olson)),
           wake_onset = force_tz(ymd_hms(wake_onset, tz = cycle_olson)),
           sleep_onset = force_tz(ymd_hms(sleep_onset, tz = cycle_olson)),) %>% ungroup() 
  
  

  
  plot_data <- plot_data %>% filter(!is.na(cycle_start) & !is.na(cycle_end) & !is.na(wake_onset))
  
  # Apply the function to the data frame
  plot_data <-  plot_data %>% mutate(grade = sapply(wake_onset, grade_mapping))
  summary(plot_data)
  

  # Apply the function to the data frame
  plot_data <-  plot_data %>% mutate(days_since = mapply(days_since_mapping, grade, as.Date(wake_onset)))
  
  #Remove time zone cols
  plot_data <- plot_data %>% select(-cycle_olson, -cycle_tzone)
  
  return(plot_data)

}

plot_data <- date_cleaning(plot_data)

melted_data <- plot_data %>% select(-c(cycle_start, cycle_end, sleep_onset )) %>% pivot_longer(cols = -c(wake_onset, grade, days_since), names_to = "metric", values_to= "value")


```

## Physiological Metrics over Years

```{r}

metric_plot <- melted_data %>% mutate(reference = ifelse(month(wake_onset) == 8, "pre season", ifelse(month(wake_onset) %in% c(5,6,7), "summer", ifelse(month(wake_onset) == 2, "conference", NA))))

metrics = c("rhr", "hrv", "maxhr", "recovery")
for (i in 1:4){
  g_metric <- ggplot(metric_plot[metric_plot$metric == metrics[i],], # Set data
              aes(x = days_since, y = value, color = grade))+ # Set aesthetics
  #geom_jitter(alpha = 0.2, height =0.1, aes(fill = metric))+ # Add points 
    
  geom_vline(xintercept = metric_plot[metric_plot$reference == "pre season",]$days_since, linetype = "dotted", color = "blue") + # Add vertical reference line
    
  geom_vline(xintercept = metric_plot[metric_plot$reference == "conference",]$days_since, linetype = "dotted", color = "green") + # Add vertical reference line
    
  geom_smooth(se = FALSE) + # Add smooting line
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + # Turn off grid
  dark_theme_minimal() + # Set theme
  labs(title = paste0("Whoop Metrics -- ", metrics[i]), # Set labels
       color = "Year") +
      annotate("text", x = 110, y = max(metric_plot[metric_plot$metric == metrics[i] & !is.na(metric_plot$value),]$value) -5, label = "pre season", color = "blue") + # Label for vertical line
    annotate("text", x = 290, y = max(metric_plot[metric_plot$metric == metrics[i] & !is.na(metric_plot$value),]$value) -5, label = "conference", color = "green") + # Label for vertical line
  guides(fill = "none") 

# Generate plot
print(g_metric)

}
# Turn off dark mode
invert_geom_defaults()

```


## Meet Overview

```{r}
all_swim <- read.csv("all_swim_results.csv")

```

```{r}
swim_df <- all_swim %>% mutate(Date = str_replace_all(Date, "â€“\\d{1,2}", ""), Results = str_replace_all(Results, "\\[|'|\\]|%|\\+", "")) %>% 
  mutate(Date = mdy(Date)) %>% 
    separate(Results, into = c("1", "2", "3"), sep = "\\), \\(", remove = TRUE) %>% 
      pivot_longer(cols = c("1", "2", "3"), names_to = "Event_Num", values_to = "Results")  %>% 
        mutate(Results = str_replace_all(Results, "\\(|\\)", "")) %>% 
          separate(Results, into = c("Event", "Time", "Season_Improvement"), sep=",") %>%
          mutate(Time = trimws(Time), Season_Improvement = trimws(Season_Improvement))  %>% 
            mutate(Season_Improvement = as.numeric(Season_Improvement))

imputed <- swim_df %>% mutate(Time = ifelse(Time == "", NA, Time), Event = ifelse(Event == "", NA, Event)) %>% mutate(Season_Improvement = ifelse(!is.na(Time) & is.na(Season_Improvement), 0, Season_Improvement))

head(imputed)
plot_bar <- imputed %>% filter(!is.na(Event)) %>% mutate(Best = ifelse(Event %in% c("100 Y Free", "50 Y Free", "100 Y Back"), 1, 0))
ggplot(data = plot_bar, aes(x=as.factor(Event), fill = as.factor(Best))) + 
  geom_bar() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  guides(fill = "none") +
  labs(title = "Distribution of Events in College", subtitle = "2020-2025", x ="events")
```

```{r}

summary_imp <- imputed %>% group_by(Date) %>% summarise(mean_imp = mean(Season_Improvement, rm.na = TRUE), max_imp = max(Season_Improvement, rm.na = TRUE)) %>% na.omit()

#get week summary for improvement so we can match it with weekly sleep and strain
summary_week <- summary_imp %>%
  mutate(week = floor_date(Date, "week")) %>%
  group_by(week) %>%
  summarise(mean_imp = mean(mean_imp),
            max_imp = max(max_imp))

summary_week$week = as.POSIXct.Date(summary_week$week)


```

## Sleep Metrics over the Years

```{r}
sleep = read.csv("sleeps.csv")
colnames(sleep) = c("cycle_start", "cycle_end", "cycle_tzone", "sleep_onset", "wake_onset", "performance", "resp_rate", "asleep_dur", "in_bed_dur", "light_sleep", "deep_sleep", "rem", "awake", "sleep_need", "sleep_debt", "efficiency", "consistency", "nap")

sleep_data <- date_cleaning(sleep)


melted_data <- sleep_data %>% select(-c(cycle_start, cycle_end, sleep_onset, nap)) %>% pivot_longer(cols = -c(wake_onset, grade, days_since), names_to = "metric", values_to= "value")

```


```{r}

metric_plot <- melted_data %>% mutate(reference = ifelse(month(wake_onset) == 8, "pre season", ifelse(month(wake_onset) %in% c(5,6,7), "summer", ifelse(month(wake_onset) == 2, "conference", NA))))

summary(metric_plot)

metrics = c("efficiency", "performance", "sleep_debt", "rem")
for (i in 1:4){
  g_metric <- ggplot(metric_plot[metric_plot$metric == metrics[i],], # Set data
              aes(x = days_since, y = value, color = grade))+ # Set aesthetics
  #geom_jitter(alpha = 0.2, height =0.1, aes(fill = metric))+ # Add points 
    
  geom_vline(xintercept = metric_plot[metric_plot$reference == "pre season",]$days_since, linetype = "dotted", color = "blue") + # Add vertical reference line
    
  geom_vline(xintercept = metric_plot[metric_plot$reference == "conference",]$days_since, linetype = "dotted", color = "green") + # Add vertical reference line
    
  geom_smooth(se = FALSE) + # Add smooting line
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + # Turn off grid
  dark_theme_minimal() + # Set theme
  labs(title = paste0("Whoop Metrics -- ", metrics[i]), # Set labels
       color = "Year") +
      annotate("text", x = 110, y = max(metric_plot[metric_plot$metric == metrics[i] & !is.na(metric_plot$value),]$value) -5, label = "pre season", color = "blue") + # Label for vertical line
    annotate("text", x = 290, y = max(metric_plot[metric_plot$metric == metrics[i] & !is.na(metric_plot$value),]$value) -5, label = "conference", color = "green") + # Label for vertical line
  guides(fill = "none") 

# Generate plot
print(g_metric)

}
# Turn off dark mode
invert_geom_defaults()
```
## Sleep on Performance
```{r}

### Sleep

plot_sleep = melted_data %>%  filter(metric %in% c("asleep_dur", "rem", "deep_sleep")) %>% mutate(week = floor_date(wake_onset, "week")) %>%
  group_by(week, metric) %>%
  summarise(mean = mean(value, na.rm = TRUE))

plot_sleep$week = as.Date(plot_sleep$week)
summary_week$week = as.Date(summary_week$week)

merged = merge(summary_week, plot_sleep, by = "week")

g_sleep1 = ggplot(merged, # Set data
              aes(y = mean, x = max_imp, color = metric)) + geom_smooth() +
  labs(x=" Max Performance Improvement %", y="Metric Mean (mins)", title = "The effect of sleep on max performance improvement") # Set aesthetics

g_sleep2 = ggplot(merged, # Set data
              aes(y = mean, x = mean_imp, color = metric)) + geom_smooth() +
  labs(x="Mean Performance Improvement %", y="Metric Mean (mins)", title = "The effect of sleep on mean performance improvement") # Set aesthetics
g_sleep1
g_sleep2
```
At the highest values of deep and REM sleep, performance either increased the most or decreased the most. This could be explained by the fact more sleep has a positive effect of performance but also more sleep can indicate some other underlying problem such as sickness or fatigue. 

## Strain on Performance

```{r}
### Strain
strain_week = plot_data %>% select(wake_onset, day_strain) %>% mutate(week =floor_date(wake_onset, "week")) %>%
  group_by(week) %>%
  summarise(strain_mean = mean(day_strain, na.rm = TRUE))

strain_week$week = as.Date(strain_week$week)
merged1 = merge(summary_week, strain_week,  by = "week")

colnames(strain_week)
g_strain1 = ggplot(merged1, # Set data
              aes(y = strain_mean, x = mean_imp)) + geom_smooth() +
  labs(x="MeanPerformance Improvement %", y= "Mean Day Strain", title = "The effect of strain on mean performance improvement") # Set aesthetics
g_strain1

g_strain2 = ggplot(merged1, # Set data
              aes(y = strain_mean, x = max_imp)) + geom_smooth() +
  labs(x="Max Performance Improvement %", y= "Mean Day Strain", title = "The effect of strain on max performance improvement") # Set aesthetics
g_strain2

```
Interestingly, there is not a linear relationship between strain and % improvement. It shows that a mean daily strain in the week leading up to my best overall performances (mean) is not the least but a little above, meaning I still kept some intensity in my workouts.

When we look at max performance improvement, which is looking at when I do the best in my best event compared to the season, for improvements 3% or better the strain in consistently around 14. But if the week strain is too low (around 11) or too high (around 15.5), then my best improvement drops off.



## Pre-Competition Workouts
```{r}
conference_dates = c(
  "Freshman" = "02-25-2021", 
  "Sophomore" = "02-22-2022",
  "Junior" = "02-13-2023",
  "Senior" = "02-22-2024")

midseason_dates = c(
  "Freshman" = "11-20-2020", 
  "Sophomore" = "11-20-2021", 
  "Junior" = "11-17-2022",
  "Senior" = "11-16-2023",
  "Grad" = "11-21-2024")


workouts = read.csv("workouts.csv")
workouts = workouts[,c(1:16)]
colnames(workouts) = c("cycle_start", "cycle_end", "cycle_tzone", "workout_start", "workout_end", "dur", "activity", "activity_strain", "cals", "max_hr", "av_hr", "zone1", "zone2", "zone3", "zone4", "zone5")

workouts$date = as.Date(workouts$workout_start)

workouts = workouts %>%
  mutate(workout_start = ymd_hms(workout_start), workout_end = ymd_hms(workout_end)) %>%
    mutate(morning = ifelse(format(workout_start, "%H:%M:%S") < "12:00:00", 1, 0))

sessions <- workouts %>%
  select(morning, activity, date, dur, activity_strain) %>% 
  group_by(date) %>%
  summarise(
    total_dur = sum(dur),
    max_strain = max(activity_strain),
    count_morning = sum(morning == 1),
    count_afternoon = sum(morning == 0)
  )

activities = workouts %>%
  group_by(date, activity) %>%
  summarise(count = n()) %>%
  ungroup() %>%   pivot_wider(names_from = activity, values_from = count, values_fill = list(count = 0))  %>%
  rename_at(vars(-date), ~ paste0(., "_count")) %>% select(date, Swimming_count, Weightlifting_count, Activity_count, Cycling_count) %>% mutate(Dryland_count = Weightlifting_count + Activity_count + Cycling_count) %>% select(date, Swimming_count, Dryland_count)


zones = workouts %>% group_by(date) %>% summarise( zone1 = sum(zone1), zone2 = sum(zone2), zone3 = sum(zone3), zone4 = sum(zone4), zone5 = sum(zone5))

 
workout_data = merge(merge(activities, sessions, by ="date"), zones, by = "date")
workout_data$date = as.Date(workout_data$date)
workout_data <-  workout_data %>% mutate(grade = sapply(date, grade_mapping)) 


pre_meet = workout_data %>% na.omit() %>% mutate(conf_date = mdy(conference_dates[grade]), midseason_date = mdy(midseason_dates[grade])) %>% filter(conf_date-21  <= date & date <= conf_date | (midseason_date-21  <= date & date <= midseason_date)) %>% 
  mutate(days_til1 = (as.numeric(difftime(conf_date, date, units = "days"))))%>% 
  mutate(days_til2 = (as.numeric(difftime(midseason_date, date, units = "days")))) %>% 
  rowwise() %>% mutate(days_til = ifelse(days_til2 >= 0, min(days_til2, days_til1), max(days_til2, days_til1))) %>% ungroup() %>% select(-days_til1, -days_til2) %>% mutate(event =ifelse( abs(difftime(conf_date, date)) > abs(difftime(midseason_date, date)),  "conference", "midseason"))

 
```

```{r}

metrics = c("max_strain", "total_dur")

  pre_plot = pre_meet %>% select(days_til, max_strain, total_dur, event, grade) %>% pivot_longer(cols = -c(days_til, event, grade), names_to = "metric", values_to = "value") 
  
  g_preconf <- ggplot(pre_plot[pre_plot$metric == metrics[1] & pre_plot$event == "conference",], # Set data
              aes(x = days_til, y = value, color = grade) )+ # Set aesthetics

    
  geom_smooth(se = FALSE) + # Add smooting line
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + # Turn off grid
  dark_theme_minimal() + # Set theme
  labs(title = "Whoop Metrics -- Pre Conference", subtitle = metrics[1], # Set labels
       color = "Year", "Max Whoop Strain per Day") +
  scale_x_reverse()

# Generate plot
print(g_preconf)
  
  g_preconf1 <- ggplot(pre_plot[pre_plot$metric == metrics[2] & pre_plot$event == "conference",], # Set data
              aes(x = days_til, y = value, color = grade) )+ # Set aesthetics

    
  geom_smooth(se = FALSE) + # Add smooting line
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + # Turn off grid
  dark_theme_minimal() + # Set theme
  labs(title = "Whoop Metrics -- Pre Conference", subtitle = metrics[2], # Set labels
       color = "Year", y = "Mins per Day")+
  scale_x_reverse()

# Generate plot
print(g_preconf1)
```
This shows how many workouts changed when approaching two major meets this year. My most successful year, Senior year, I kept at least one of my practices with high intensity and dropped that intensity dramatically with around a week to go. There was a similar pattern with total workout duration per day, but the drop happened early around 10 days previous.

```{r}
  g_premid <- ggplot(pre_plot[pre_plot$metric == metrics[1] & pre_plot$event == "midseason",], # Set data
              aes(x = days_til, y = value, color = grade) )+ # Set aesthetics

    
  geom_smooth(se = FALSE) + # Add smooting line
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + # Turn off grid
  dark_theme_minimal() + # Set theme
  labs(title = "Whoop Metrics -- Pre Mid", subtitle = metrics[1], # Set labels
       color = "Year", "Max Whoop Strain per Day")+
  scale_x_reverse()

# Generate plot
print(g_premid)


  
  g_premid1 <- ggplot(pre_plot[pre_plot$metric == metrics[2] & pre_plot$event == "midseason",], # Set data
              aes(x = days_til, y = value, color = grade) )+ # Set aesthetics

    
  geom_smooth(se = FALSE) + # Add smooting line
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + # Turn off grid
  dark_theme_minimal() + # Set theme
  labs(title = "Whoop Metrics -- Pre Mid", subtitle = metrics[2], # Set labels
       color = "Year", y = "Mins per Day")+
  scale_x_reverse()

# Generate plot
print(g_premid1)

```
There is a lot less significant pattern approaching mid-season as there is less emphasis on resting for this meet. Interesting my best two years, junior and senior, had completely different approaches to taper.

## EDA Findings

Based on my EDA and my knowledge of how I have swam over the years, there are certain factors that seem to affect my performance. I will use these derived variables for the time leading into meets

**From the sleep metrics:**
- REM sleep (week before)
- Deep sleep (week before)
- Sleep efficiency (week before)

**From workout metrics:**
- mean daily workout duration (2 weeks before)
  - swims
  - mornings
- mean daily strain (2 weeks before)
- max daily workout strain (2 weeks before)
- A:C ratio for each aerobic zone (7:28)

**From physiology metrics:**
- mean max daily HR
- mean RHR
- mean HRV






```{r Get top 5 event results as output for model}
library(readxl)
top5 <- read_excel("swim_top5.xlsx") %>%
  group_by(Date, Event) %>%
  mutate(SwimNum = dense_rank(desc(row_number()))) 

back2 <- read.delim("./back2.txt", comment.char="#")

back2 <- back2 %>% select(-X) %>% separate(Time, into = c("Min", "Sec"), sep = ":") %>% mutate(Time = as.numeric(Min)*60 + as.numeric(Sec), Event = "200 Y Back", Date = mdy(Date)) %>% select(-Min, -Sec) %>% 
  group_by(Date, Event) %>%
  mutate(SwimNum = dense_rank(desc(row_number()))) 

top5 <- rbind(top5, back2)

top5 %>% ungroup()
top5 <- top5  %>% group_by(Event) %>% arrange(Event, Date, SwimNum)
pb = 1000
pb_col = c() 
imp_col = c()
prev_event = ""

for (i in 1:nrow(top5)) {
  row <- top5[i, ]
  event = row$Event
  
  if (event == prev_event & row$Time <= pb){
      pb_col = c(pb_col, 1)
      
      imp = -(top5[i, ]$Time - pb)/top5[i, ]$Time
      
      imp_col = c(imp_col, imp)
      
      pb = top5[i, ]$Time
  } else if(event != prev_event){ #first time swam new event
    
      pb_col = c(pb_col, 1)
      imp_col = c(imp_col, 0)
      pb = top5[i, ]$Time
  } else {
      pb_col = c(pb_col, 0)
      imp = -(top5[i, ]$Time - pb)/top5[i, ]$Time
      imp_col = c(imp_col, imp)

  }
  
  prev_event = row$Event
  
  
}
top5$PB = pb_col
top5$Imp= imp_col
head(top5)
```
To do:
- derive ac ratios for all zones, strains
- derive lags for all sleep
- count number of workouts, mornings in lag
- run models for all and individual events

- cluster performances by metrics do any performances stand out?
- lasso correlation between imp and anything?


#days until all meets and take 21 or 14?

## Final Dataframe

```{r}
library(mice)
all_whoop <- inner_join(sleep_data, plot_data)
all_whoop$date = as.Date(all_whoop$wake_onset)

all_whoop <- left_join(all_whoop, workout_data)
summary(all_whoop)

all_whoop <- all_whoop %>% mutate(date = as.Date(wake_onset))

all_whoop <- all_whoop %>% 
  mutate(across(34:44, ~ifelse(is.na(.), 0, .))) #impute NA workout data with 0-- I did no workout


#Derive some more variables
all_whoop <- all_whoop %>% arrange(date) %>% mutate(waking_hours = as.numeric(difftime(time1= as.POSIXct(wake_onset), time2 =as.POSIXct(sleep_onset), units = 'hours')))

```

## Imputation

```{r Dealing with NAs}
#Lets remove some NAs
#Need to impute sleep consistency, consistency and day strain
all_whoop <- all_whoop %>% filter(!is.na(grade)) %>% select(-blood_oxygen, -resp_rate, -skin_temp)

#Separate into numeric and non numeric
numeric <- all_whoop %>% select_if(is.numeric)
not_numeric <- all_whoop %>% select_if(~ !is.numeric(.))

correlation_matrix <- cor(numeric, use = "complete.obs")
which(correlation_matrix == 1, arr.ind = TRUE) #Lets look for perfect correlations
```

We can see that sleep consistency and consistency, and awake and awake_dur are perfectly correlated so we don't need both of them. Let's remove sleep consistency


```{r}
#Remove sleep consistency
numeric <- numeric %>% select(-sleep_consistency, -awake)

#Impute remaining NAs in consistency and day strain with MICE
imputed_data <- mice(numeric, m = 5, method = 'pmm', maxit = 50, seed = 500, print=FALSE)

sum(is.na(imputed_data))

complete_numeric <- complete(imputed_data, 1)

sum(is.na(complete_numeric))

whoop_imputed <- cbind(not_numeric, complete_numeric)
sum(is.na(whoop_imputed))

dim(whoop_imputed)[1] == dim(all_whoop)[1] #they are still the same length
```

We have dealt with all NAs.


Now we can create all other derived variables:

## Derived Variables

### AC Ratio

```{r}


#Lets split metric-admin for AC ratio
#I want to look at aerobic zones, total_dur, counts and day strain
#Look over ratios: 3:7, 7:21

met_data <- all_whoop %>% select(zone1, zone2, zone3, zone4, zone5, day_strain, Swimming_count, Dryland_count, total_dur, count_morning, count_afternoon) 
admin_dat <- all_whoop %>% select(-c(zone1, zone2, zone3, zone4, zone5, day_strain, Swimming_count, Dryland_count, total_dur, count_morning, count_afternoon)) %>% rename(days = days_since)

```


```{r AC ratio}
sum_days <- function(met_data, admin_dat, met, days){
  #'
  #' This function calculates the sum of a given metric over a 
  #' period of time.
  #'
  #' @param met_data Data frame of metrics over a given period
  #' @param admin_data Data frame of adminstration variables, with 
  #' columns of players, indicating player id, and days, indicating the
  #' day each metric was measured on
  #' @param met The metric to calculate the sum for
  #' @param days The time window to calculate the sum for
  #' 
  #' @return A vector containing the summed variable over the 
  #' previous days period for each row.
  #'
  #' @examples
  #' g_data <- data.frame(distance = c(1,2,3,4))
  #' a_data <- data.frame(players = c(1,1,1,1),
  #'                          days = c(1,2,3,4))
  #' sum_res <- sum_days(met_data = g_data,
  #'                     admin_dat = a_data,
  #'                     met = "distance",
  #'                     days = 2)
  #'
  
  # Create empty vector to store results
  sum_vec <- rep(NA, nrow(met_data))
  # For each row of results data frame
  for(i in 1:nrow(met_data)){
    # Extract previous data which falls in given window, for given metric
    temp_vec <- met_data[which(admin_dat$days < admin_dat$days[i] &
                               admin_dat$days >= (admin_dat$days[i] - days)),c(met)]
    # If the length of this vector is at least 1
    if(length(temp_vec) >= 1){
      # Calculate sum of the values and assign to result vector
      sum_vec[i] <- sum(temp_vec, na.rm = T)
    }
  }
  # Return result vector
  return(sum_vec)
}

```


```{r}
ac_ratio <- function(met_data, admin_dat, met, days_1, days_2){
  #'
  #' This function calculates the acute:chronic ratio for a given 
  #' metric over a set time period. 
  #' 
  #' @param met_data A data frame containing metric values
  #' @param admin_data Data frame of adminstration variables, with 
  #' columns of players, indicating player id, and days, indicating the
  #' day each metric was measured on.
  #' @param met The metric of interest
  #' @param days_1 - The number of days to use for the acute window
  #' @param days_2 - The number of days to use for the chronic window
  #'
  #' @return A vector of the acute chronic window corresponding to each
  #' row in met_data and admin_db
  #'
  #' @examples
  #' g_data <- data.frame(distance = c(1,2,3,4))
  #' a_data <- data.frame(players = c(1,1,1,1),
  #'                          days = c(1,2,3,4))
  #' ac_res <- ac_ratio(met_data = g_data,
  #'                    admin_dat = a_data,
  #'                    met = "distance",
  #'                    days_1 = 1,
  #'                    days_2 = 2)
  #'
  
  # Calculate the sum of values for the acute window
  sum_vec_1 <- sum_days(met_data, admin_dat, met = met, days = days_1)
  # Calculate the sum of values for the chronic window
  sum_vec_2 <- sum_days(met_data, admin_dat, met = met, days = days_2)
  # Modify the chronic vector to same level as acute
  mod_sum_vec_2 <- sum_vec_2 * (days_1/days_2)
  # Calculate AC ratio
  ac_ratio <- sum_vec_1/mod_sum_vec_2
  # Return ac ratio vector
  return(ac_ratio)
}



```



```{r}
# Create empty data frames to store our results
sum_7_res <- sum_3_res <- sum_14_res <- ac_7_21_res <- ac_3_7_res <-  as.data.frame(matrix(NA, nrow = nrow(met_data), ncol = ncol(met_data)))


# For each column in the gps data
for(i in 1:ncol(met_data)){
  # Calculate the sum over 3 days
  sum_3_res[,i] <- sum_days(met_data, # Set GPS data
                            admin_dat,  # Set Admin data
                            met = names(met_data)[i], # Set metric to use
                            days = 7) # Set window size
  
  # Calculate the sum over 7 days
  sum_7_res[,i] <- sum_days(met_data, # Set GPS data
                             admin_dat,  # Set admin data
                             met = names(met_data)[i], # Set metric to use
                             days = 28) # Set window size
  
  # Calculate the sum over 14 days
  sum_14_res[,i] <- sum_days(met_data, # Set GPS data
                             admin_dat, # Set admin data
                             met = names(met_data)[i], # Set metric to use
                             days = 56) # Set window size
  
  # Calculate the A:C ratio for 7:21
  ac_7_21_res[,i] <- ac_ratio(met_data, # Set GPS data
                              admin_dat, # Set admin data
                              met = names(met_data)[i], # Set metric to use
                              days_1 = 7, # Set acute window
                              days_2 = 21) # Set chronic window
  
  # Calculate the A:C ratio for 3:7
  ac_3_7_res[,i] <- ac_ratio(met_data, # Set GPS data
                               admin_dat, # Set admin data
                               met = names(met_data)[i], # Set metric to use
                               days_1 = 3, # Set acute window
                               days_2 = 3) # Set chronic window
  
}
```

Next up we need to fix the names of the result data frames we have calculated so that we can tell which metric is which:

```{r}
# Set names for 7 day sums
names(sum_7_res) <- paste(names(met_data), "_sum_7_days", sep="")
# Set names for 28 day sums
names(sum_14_res) <- paste(names(met_data), "_sum_14_days", sep="")
# Set names for 56 day sums
names(sum_3_res) <- paste(names(met_data), "_sum_3_days", sep="")
# Set names for A:C 7:21
names(ac_7_21_res) <- paste(names(met_data), "_ac_7_21", sep="")
# Set names for A:C 28:56
names(ac_3_7_res) <- paste(names(met_data), "_ac_3_7", sep="")

```

Finally we want to rejoin all our data together so that we have a single data frame to work with:

```{r}
# Join data together
met_dat <- cbind.data.frame(met_data, sum_3_res, sum_7_res, sum_14_res, ac_3_7_res, ac_7_21_res)

dim(met_dat)
dim(admin_dat)

all_whoop_1 <- cbind.data.frame(admin_dat, met_dat)

```


### Sleep Lag

in_bed_dur, awake_dur, asleep_dur, deep_sleep, rem, sleep_need, sleep_debt, sleep_performance, waking_hours



```{r}
sleep_met <- all_whoop_1 %>% select(in_bed_dur, awake_dur, asleep_dur, deep_sleep, rem, sleep_need, sleep_debt, sleep_performance, waking_hours)

sleep_admin <- all_whoop_1 %>% select(-c(in_bed_dur, awake_dur, asleep_dur, deep_sleep, rem, sleep_need, sleep_debt, sleep_performance, waking_hours))
```


```{r}

lag_metric_calculator <- function(metric_data, lagged_days = 3,
                                  metric = "in_bed_dur",
                                  include_current = TRUE){
  #'
  #' This function carries out calculations on lagged values of a given
  #' metric
  #' 
  #' @param metric_data The data frame containing the metrics of interest
  #' @param lagged_days How many lagged days to use in the calculations
  #' @param metric The metric to create the calculations for 
  #' @param include_current Should the current day be included in the 
  #' calculation
  #'
  #' @return This function returns a data frame containing the calculated mean,
  #' sum, max, and min for the set time period (lagged_days). It also calculates
  #' how many values were missing in that time period. 
  #'
  
  # Extract vector to lag
  met_vec <- unlist(metric_data[,metric])
  
  if(include_current){
    # Create empty data frame to store results
    res_data <- matrix(NA, nrow = nrow(metric_data), ncol = lagged_days + 1)
    
    # Add current column to res_data
    res_data[,lagged_days + 1] <- met_vec
  } else{
     # Create empty data frame to store results
    res_data <- matrix(NA, nrow = nrow(metric_data), ncol = lagged_days)
  
  }
  
  
  # Loop through days and calculate lagged values
  for(i in 1:lagged_days){
    # Store lagged values
    res_data[,i] <- lag(x = met_vec, n = i)
  }
  
  # Calculate results for each day:
  mean_val <- rowMeans(res_data, na.rm = TRUE) # Calculate mean value
  sum_val <- rowSums(res_data, na.rm = TRUE) # Calculate sum value
  max_val <- rowMaxs(res_data, na.rm = TRUE) # Calculate max value
  min_val <- rowMins(res_data, na.rm = TRUE) # Calculate min value
  
  # Combine results vector
  results <- cbind.data.frame(mean_val, sum_val, max_val, min_val)
  
  # Handle the infinite values for max and min calculations
  results$max_val[is.infinite(results$max_val)] <- NA
  results$min_val[is.infinite(results$min_val)] <- NA
  
  
  names(results) <- paste(names(results), "_lag_", as.character(lagged_days+1), "_res", sep="")
  
  # Return results
  return(results)
}
```

```{r, eval=FALSE}

sleep_metrics = c('in_bed_dur', 'awake_dur', 'asleep_dur', 'deep_sleep', 'rem', 'sleep_need', 'sleep_debt', 'sleep_performance', 'waking_hours')
sleep_lags = data.frame()

lag_3_res <- lag_7_res <- lag_14_res <-  as.data.frame(matrix(NA, nrow = nrow(sleep_met), ncol = 5))

for (i in seq(1:length(sleep_metrics))){
  lag_3_res <- lag_7_res <- lag_14_res <-  as.data.frame(matrix(NA, nrow = nrow(sleep_met), ncol = 5))

  lag_3_res <- lag_metric_calculator(sleep_met, lagged_days = 2,
                                    metric = sleep_metrics[i],
                                    include_current = TRUE)
  lag_7_res <- lag_metric_calculator(sleep_met, lagged_days = 6,
                                    metric = sleep_metrics[i],
                                    include_current = TRUE)
  lag_14_res <- lag_metric_calculator(sleep_met, lagged_days = 13,
                                    metric = sleep_metrics[i],
                                    include_current = TRUE)
  
  # Set names for 3 day
  names(lag_3_res) <- paste(sleep_metrics[i], "_", names(lag_3_res),sep="")
  # Set names for 7 day
  names(lag_7_res) <- paste(sleep_metrics[i], "_", names(lag_7_res),sep="")
  # Set names for 14 day
  names(lag_14_res) <- paste(sleep_metrics[i], "_", names(lag_14_res),sep="")
  
  if (nrow(sleep_lags) == 0){
    sleep_lags = cbind.data.frame(lag_3_res, lag_7_res, lag_14_res)
  } else {
    sleep_lags = cbind.data.frame(sleep_lags, lag_3_res, lag_7_res, lag_14_res)
  }
  
    
  
}
```


```{r}
dim(sleep_met)
dim(sleep_admin)
dim(sleep_lags)

all_whoop_2 <- cbind.data.frame(sleep_admin, sleep_met, sleep_lags)

#Drop naps as only "false"
all_whoop_2 <- all_whoop_2 %>% select(-nap)
summary(all_whoop_2)

colnames(all_whoop_2)

```
Still got to look at HRs and whoop metrics


## Next Ideas: 

cumulative sum of mornings/swims
a:C ratio for anything, aerobic zones 7:28
weekend vs weekday